{"pages":[{"title":"","text":"This is everything about me","link":"/about/index.html"}],"posts":[{"title":"领域自适应综述","text":"温故知新篇 – 领域自适应中的多种方法和内部含义浅析 领域自适应定义： 现有深度学习模型使用源域的知识，并运用一系列领域自适应方法，提升其在目标域上的表现。基于研究领域自适应问题本质为研究泛化问题，其有众多的应用方向，包括但不限于分类，目标检测，语义分割等。 如何做到领域自适应： 为了能回答这个问题，我们需要先回答另外一个问题，如何理解领域自适应问题。 如何理解领域自适应：首先，我们可以来看一下，什么样的情况会导致领域不适应；接着，我们来使用自己建立的数学模型来理解领域不适应时到底发生了什么；最后我们引出，基于这个数学模型，我们如何来理解现有的多种领域自适应方法。 领域不适应的情形：领域不适应，即神经网络的泛化性能较差，其在以下情形容易发生： 神经网络模型对于训练集分布过拟合：网络在训练集上的指标和测试集上指标差异达到5%及以上，并且随着训练的进行差异越来越大。 测试集分布和训练集分布差异较大：我们发现，在生成图像上训练的模型，在真实图片上训练效果很差。这时，我们会说神经网络在测试集上的表现性能差，我们称这个神经网络模型的泛化性能差。那么，如何从数学模型的角度来理解泛化的问题呢？ 数学模型解释泛化： 我们不妨先假设我们在进行分类问题，同时我们将数据的分布降为两维，而不是图像的千万维，那么分类问题即在二维平面上寻找一条分界线，将两个不同的标记的类别进行区分。 神经网络对于训练集过拟合：这个情形我们应当很熟悉了，此时分界线在训练集的不同类别之间交叉穿过，但是由于测试集的分布和训练集不同，因此产生了大量的错误分类。这时，我们的问题在于分界线的复杂度太高，超过了数据本身真实分布需要的分界线，或者可以说模型的复杂度和真实分界线的复杂度之间有维度差距 测试集和训练集分布差异大：这时我们可以想象一个适当复杂度的分界线对训练集的不同类别进行分类，但是测试集和训练集的分布有差异。同样的类别，但是产生了分布偏移，甚至和原来的类别差异较远。说明当前用于训练神经网络模型的数据分布不能反映真实数据的分布。从而生成的分界线不能正确分割真实数据。从上分析我们可以看出，领域自适应的问题，本质就是数据分布和分界线的问题，一个良好的领域自适应方法应当同时兼顾对齐源域和目标域的数据分布，同时对分界线进行约束。从而源域和目标域的数据分布对齐良好，同时模型的分界边界","link":"/2020/05/06/Adaptation/"}],"tags":[{"name":"领域自适应","slug":"领域自适应","link":"/tags/%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94/"}],"categories":[{"name":"领域自适应","slug":"领域自适应","link":"/categories/%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94/"}]}