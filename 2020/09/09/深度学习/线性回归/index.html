<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>线性回归 - Digital Shiyu</title><meta description="线性回归（基于神经网络+梯度下降）定义：基于特征和标签之间的线性函数关系约束，线性回归通过建立单层神经网络，将神经网络中每一个神经元当成是函数关系中的一个参数，通过利用初始输出和目标输出建立损失，并优化损失最小的方式使得神经元的数值和真实函数参数数值最相近，从而通过网络训练得到最符合数据分布的函数关系。 实施步骤：  初始通过随机化线性函数的参数，通过输入的x，会得到一系列y_h 输出的y_h和真"><meta property="og:type" content="blog"><meta property="og:title" content="线性回归"><meta property="og:url" content="http://yoursite.com/2020/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><meta property="og:site_name" content="Digital Shiyu"><meta property="og:description" content="线性回归（基于神经网络+梯度下降）定义：基于特征和标签之间的线性函数关系约束，线性回归通过建立单层神经网络，将神经网络中每一个神经元当成是函数关系中的一个参数，通过利用初始输出和目标输出建立损失，并优化损失最小的方式使得神经元的数值和真实函数参数数值最相近，从而通过网络训练得到最符合数据分布的函数关系。 实施步骤：  初始通过随机化线性函数的参数，通过输入的x，会得到一系列y_h 输出的y_h和真"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://yoursite.com/gallery/LinearR.png"><meta property="article:published_time" content="2020-09-09T07:56:10.000Z"><meta property="article:modified_time" content="2020-09-15T01:32:28.632Z"><meta property="article:author" content="shiyu AllRightsReserved"><meta property="article:tag" content="最小二乘法"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/LinearR.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://yoursite.com/2020/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"},"headline":"Digital Shiyu","image":["http://yoursite.com/gallery/LinearR.png"],"datePublished":"2020-09-09T07:56:10.000Z","dateModified":"2020-09-15T01:32:28.632Z","author":{"@type":"Person","name":"shiyu AllRightsReserved"},"description":"线性回归（基于神经网络+梯度下降）定义：基于特征和标签之间的线性函数关系约束，线性回归通过建立单层神经网络，将神经网络中每一个神经元当成是函数关系中的一个参数，通过利用初始输出和目标输出建立损失，并优化损失最小的方式使得神经元的数值和真实函数参数数值最相近，从而通过网络训练得到最符合数据分布的函数关系。 实施步骤：  初始通过随机化线性函数的参数，通过输入的x，会得到一系列y_h 输出的y_h和真"}</script><link rel="canonical" href="http://yoursite.com/2020/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"><link rel="icon" href="/img/digitalpre.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-165282104-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-165282104-1');</script><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/Digital.png" alt="Digital Shiyu" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">存档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/gallery/LinearR.png" alt="线性回归"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-09-09T07:56:10.000Z" title="2020-09-09T07:56:10.000Z">2020-09-09</time><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">9 分钟 读完 (大约 1378 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">线性回归</h1><div class="content"><h1 id="线性回归（基于神经网络-梯度下降）"><a href="#线性回归（基于神经网络-梯度下降）" class="headerlink" title="线性回归（基于神经网络+梯度下降）"></a>线性回归（基于神经网络+梯度下降）</h1><p><strong>定义</strong>：基于特征和标签之间的线性函数关系约束，线性回归通过建立单层神经网络，将神经网络中每一个神经元当成是函数关系中的一个参数，通过利用初始输出和目标输出建立损失，并优化损失最小的方式使得神经元的数值和真实函数参数数值最相近，从而通过网络训练得到最符合数据分布的函数关系。</p>
<p><strong>实施步骤</strong>：</p>
<ol>
<li>初始通过随机化线性函数的参数，通过输入的x，会得到一系列y_h</li>
<li>输出的y_h和真实值y之间因为神经元参数不正确产生差距，为了y_h和y能尽量地逼近，我们通过平方误差损失函数（MSE Loss）来描述这种误差。</li>
<li>类似于通过求导得到损失函数最优解的方式，我们通过梯度下降法将这种误差传递到参数，通过调整参数使误差达到最小</li>
<li>通过几轮的训练，我们得到的最小的损失值对应的神经元数值，就是描述输入输出的线性关系的最好的参数。</li>
</ol>
<a id="more"></a>

<p><strong>要点</strong>：</p>
<ol>
<li>确定输入输出之间一定满足线性关系，这一点可以通过对x,y画图看出，只有线性关系才能使用线性回归训练得到</li>
<li>由于线性关系唯一由神经元个数决定，不同的参数个数唯一决定了这种线性关系，因此需要选择适合的特征用于线性回归</li>
</ol>
<h2 id="最小二乘法（基于数据计算得到解析解的线性回归）"><a href="#最小二乘法（基于数据计算得到解析解的线性回归）" class="headerlink" title="最小二乘法（基于数据计算得到解析解的线性回归）"></a>最小二乘法（基于数据计算得到解析解的线性回归）</h2><p>参考shuhuai的<a href="https://www.bilibili.com/video/BV1aE411o7qd?p=9">视频</a></p>
<p><img src="/Pics/minmul.png" alt="img"></p>
<p><strong>定义</strong>：最小二乘法是希望对 n 维平面的线性数据进行拟合得到输入输出的线性函数，其思想是建立一个线性模型 </p>
<p>![](<a href="http://latex.codecogs.com/gif.latex?\\frac{\\partial">http://latex.codecogs.com/gif.latex?\\frac{\\partial</a> J}{\partial \theta_k^{(j)}}=\sum_{i:r(i,j)=1}{\big((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\big)x_k^{(i)}}+\lambda \xtheta_k^{(j)})</p>
<p>$$y = w_{1}x + … + w_{k}x + b $$ 进行预测并使得预测的损失最小，其中损失函数为 $$L = \sum_{i}(y_{i}-y_{i}) = \sum_i(y_{i}-w^{T}x_{i})  $$ 我们可以采用多种方式对这个损失函数进行优化</p>
<h3 id="1-矩阵推导出最小二乘解析解"><a href="#1-矩阵推导出最小二乘解析解" class="headerlink" title="1. 矩阵推导出最小二乘解析解"></a>1. 矩阵推导出最小二乘解析解</h3><p>将损失函数化成矩阵表示，之后令损失函数对w求导得0，求得最优解，过程如下：<br><img src="/Pics/minmulcal.png" alt="img"></p>
<h3 id="2-利用函数求导方式求得最小二乘估计解析解"><a href="#2-利用函数求导方式求得最小二乘估计解析解" class="headerlink" title="2. 利用函数求导方式求得最小二乘估计解析解"></a>2. 利用函数求导方式求得最小二乘估计解析解</h3><p>除了表示成矩阵的形式，我们也可以直接对损失函数进行化简，求得使得损失函数最小的参数值，这个部分更容易推导</p>
<ol>
<li>离差是一个凸函数<br><img src="/Pics/ressquare.svg" alt="image.png"></li>
<li>对凸函数里面的参数求导得到全局损失最小值对应的参数<br><img src="/Pics/res.svg" alt="image.png"><br><img src="/Pics/res1.svg" alt="image.png"></li>
</ol>
<h3 id="3-最小二乘估计的集合解释"><a href="#3-最小二乘估计的集合解释" class="headerlink" title="3. 最小二乘估计的集合解释"></a>3. 最小二乘估计的集合解释</h3><ol>
<li>最小二乘法实际上第一种形象的解释就是求出最能拟合数据点的直线，而最能拟合则使用数据到直线的离差最小的方式来表示</li>
<li>第二种集合解释则是从线性代数的角度出发：<ol>
<li>将 N * p维的数据 X 想象成一个 p 维子空间的的基，</li>
<li>由于 y 不能完全由这 p 维数据线性表出，因此 y 则在这个 p 维子空间的外面，</li>
<li>而我们求得的 $y^{hat}$ 则是这个 p 维子空间里离 y 最近的向量，即 y 在子空间中的投影，</li>
<li>而损失则是 y 和投影之间的差距，即投影的法向量，</li>
<li>这样使得法向量最小，可以求得和矩阵表达求解析解里面相同的结果。</li>
</ol>
</li>
</ol>
<p><img src="/Pics/minmulexp.png" alt="img"></p>
<h3 id="4-概率角度的最小二乘估计"><a href="#4-概率角度的最小二乘估计" class="headerlink" title="4. 概率角度的最小二乘估计"></a>4. 概率角度的最小二乘估计</h3><p><img src="/Pics/MLE1.png" alt="IMG"><br>当使用$$y = w^{\top}x + \epsilon $$, $$\epsilon \sim N(0,\sigma^{2})$$ 表达输入输出的关系，并进一步利用此关系进行最大似然估计时，我们发现可以得到和上述相同的损失的表达式，这也就说明，当使用最大二乘估计时，其概率视角就是<strong>在噪声为高斯分布的基础上进行最大似然估计的结果</strong>。<br><img src="/Pics/MLE2.png" alt="IMG"></p>
<h2 id="这一节中出现的有用的函数"><a href="#这一节中出现的有用的函数" class="headerlink" title="这一节中出现的有用的函数"></a>这一节中出现的有用的函数</h2><ol>
<li>使用plt绘制散点图</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(features[:, <span class="number">1</span>].numpy(), labels.numpy(), <span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<ol start="2">
<li>自行制作dataLoader: dataloader 为输入dataset可以随机获取dataset中batch size 个样本<blockquote>
<p>通过使用打乱的indices，每次yield batch size个样本，生成的生成器可以用for调用</p>
</blockquote>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span>  random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter</span><span class="params">(batch_size, features, labels)</span>:</span></span><br><span class="line">    num_examples = len(features)</span><br><span class="line">    indices = list(range(num_examples))</span><br><span class="line">    random.shuffle(indices)  <span class="comment"># random read 10 samples</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])</span><br><span class="line">        <span class="comment"># the last time may be not enough for a whole batch</span></span><br><span class="line">        <span class="keyword">yield</span>  features.index_select(<span class="number">0</span>, j), labels.index_select(<span class="number">0</span>, j)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>参数初始化：自行初始化网络中的参数，使用init模块</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"></span><br><span class="line">init.normal_(net[<span class="number">0</span>].weight, mean=<span class="number">0.0</span>, std=<span class="number">0.01</span>)</span><br><span class="line">init.constant_(net[<span class="number">0</span>].bias, val=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/">最小二乘法</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5eb231c0b704b50012abfbd8&amp;product=inline-share-buttons" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/09/09/%E6%97%A5%E6%9C%89%E6%89%80%E6%80%9D/post/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">思考</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Adaptation/"><span class="level-item">领域自适应综述</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="is-rounded" src="/img/avatar_new.jpg" alt="诗雨"></figure><p class="title is-size-4 is-block line-height-inherit">诗雨</p><p class="is-size-6 is-block">计算机视觉研究</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>地球, 银河系</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">6</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shiyutang" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shiyutang"><i class="fab fa-github-alt"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Notion" href="https://www.notion.so/shiyu00daisy/20b9186805954f9fb5c7560b73147c74"><i class="fab fa-book"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/cpp/"><span class="level-start"><span class="level-item">cpp</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%80%9D%E8%80%83/"><span class="level-start"><span class="level-item">思考</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%A7%81%E9%97%BB/"><span class="level-start"><span class="level-item">见闻</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94/"><span class="level-start"><span class="level-item">领域自适应</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><a class="media-left" href="/2020/09/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CAG_UDA/"><p class="image is-64x64"><img class="thumbnail" src="/gallery/CAG_TEASOR.png" alt="CAG_UDA"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-15T01:34:11.000Z">2020-09-15</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/15/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CAG_UDA/">CAG_UDA</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94/">领域自适应</a></p></div></article><article class="media"><a class="media-left" href="/2020/09/12/CPP/%E4%BD%BF%E7%94%A8%E5%AD%97%E7%AC%A6%E4%B8%B2/"><p class="image is-64x64"><img class="thumbnail" src="/gallery/cpp.png" alt="使用字符串"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-12T09:20:31.000Z">2020-09-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/12/CPP/%E4%BD%BF%E7%94%A8%E5%AD%97%E7%AC%A6%E4%B8%B2/">使用字符串</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/cpp/">cpp</a></p></div></article><article class="media"><a class="media-left" href="/2020/09/12/CPP/%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0cpp/"><p class="image is-64x64"><img class="thumbnail" src="/gallery/cpp.png" alt="开始学习C++"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-12T08:15:01.000Z">2020-09-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/12/CPP/%E5%BC%80%E5%A7%8B%E5%AD%A6%E4%B9%A0cpp/">开始学习C++</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/cpp/">cpp</a></p></div></article><article class="media"><a class="media-left" href="/2020/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><p class="image is-64x64"><img class="thumbnail" src="/gallery/senet.png" alt="注意力机制"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-09T09:29:55.000Z">2020-09-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">注意力机制</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><a class="media-left" href="/2020/09/09/%E6%89%80%E8%A7%81%E6%89%80%E9%97%BB/post/"><p class="image is-64x64"><img class="thumbnail" src="/gallery/test.png" alt="见闻"></p></a><div class="media-content size-small"><p><time dateTime="2020-09-09T08:33:24.000Z">2020-09-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/09/09/%E6%89%80%E8%A7%81%E6%89%80%E9%97%BB/post/">见闻</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/%E8%A7%81%E9%97%BB/">见闻</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">五月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"><span class="tag">字符串</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95/"><span class="tag">最小二乘法</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"><span class="tag">注意力机制</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%BC%E8%BF%B0/"><span class="tag">综述</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F/"><span class="tag">表达式</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"><span class="tag">论文阅读</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/Digital.png" alt="Digital Shiyu" height="28"></a><p class="size-small"><span>&copy; 2020 shiyu AllRightsReserved</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://yoursite.com',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>